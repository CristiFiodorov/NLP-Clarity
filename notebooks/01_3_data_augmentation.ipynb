{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nlpaug nltk numpy pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.word as naw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "AUGMENTED_PATH = DATA_DIR / \"train_augmented.csv\"\n",
    "\n",
    "BASE_DRIVE_DIR = Path(\"/content/drive/MyDrive/NLP-Clarity\")\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_DIR = BASE_DRIVE_DIR / \"data\"\n",
    "    TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "    AUGMENTED_PATH = DATA_DIR / \"train_augmented.csv\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not TRAIN_PATH.exists():\n",
    "    print(f\"File not found: {TRAIN_PATH}\")\n",
    "    if Path(\"data/train.csv\").exists():\n",
    "         TRAIN_PATH = Path(\"data/train.csv\")\n",
    "         AUGMENTED_PATH = Path(\"data/train_augmented.csv\")\n",
    "\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "\n",
    "label_counts = df['evasion_label'].value_counts()\n",
    "print(\"\\nClass distribution:\")\n",
    "print(label_counts)\n",
    "\n",
    "label_counts.plot(kind='bar', title='Original Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# aug_p=0.3 => 30% of words will be candidates for replacement\n",
    "aug = naw.SynonymAug(aug_src='wordnet', aug_p=0.3)\n",
    "\n",
    "def augment_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    try:\n",
    "        res = aug.augment(text)\n",
    "        return res[0] if isinstance(res, list) else res\n",
    "    except Exception as e:\n",
    "        return text\n",
    "\n",
    "text = \"The president decided to ignore the question about the economy.\"\n",
    "print(f\"Original: {text}\")\n",
    "print(f\"Augmented: {augment_text(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COUNT = 1000\n",
    "augmented_rows = []\n",
    "\n",
    "for label, count in label_counts.items():\n",
    "    if count >= TARGET_COUNT:\n",
    "        continue\n",
    "        \n",
    "    n_needed = TARGET_COUNT - count\n",
    "    print(f\"Augmenting '{label}': need {n_needed} more samples\")\n",
    "    \n",
    "    class_df = df[df['evasion_label'] == label]\n",
    "    \n",
    "    generated = 0\n",
    "    class_rows = class_df.to_dict('records')\n",
    "    \n",
    "    with tqdm(total=n_needed) as pbar:\n",
    "        while generated < n_needed:\n",
    "            for row in class_rows:\n",
    "                if generated >= n_needed:\n",
    "                    break\n",
    "                \n",
    "                new_row = row.copy()\n",
    "                \n",
    "                new_row['question'] = augment_text(row['question'])\n",
    "                new_row['interview_answer'] = augment_text(row['interview_answer'])\n",
    "                \n",
    "                augmented_rows.append(new_row)\n",
    "                generated += 1\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.DataFrame(augmented_rows)\n",
    "df_final = pd.concat([df, df_aug], ignore_index=True)\n",
    "\n",
    "# Shuffle\n",
    "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"New shape: {df_final.shape}\")\n",
    "print(\"\\nNew Class distribution:\")\n",
    "print(df_final['evasion_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(AUGMENTED_PATH, index=False)\n",
    "print(f\"Saved augmented dataset to {AUGMENTED_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
