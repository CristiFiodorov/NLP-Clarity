{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5v5cagLi4A6",
        "outputId": "8f043256-c0dc-4531-e3f8-1f2245ebbe4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Alex\\miniconda3\\envs\\312-cuda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "W0108 23:08:03.823000 7620 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from datasets import load_dataset, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    RobertaTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import json\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "MODELS_DIR = Path(\"models/roberta\")\n",
        "BASE_DRIVE_DIR = Path(\"/content/drive/MyDrive/NLP-Clarity\")\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    MODELS_DIR = BASE_DRIVE_DIR / \"models\" / \"roberta\"\n",
        "\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_MYyOa9i4A6",
        "outputId": "1fe128c7-d7da-466f-c830-a807da620742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 3103, Val: 345, Test: 308\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_DIR = BASE_DRIVE_DIR / \"data\"\n",
        "\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_path = DATA_DIR / \"train.csv\"\n",
        "val_path = DATA_DIR / \"val.csv\"\n",
        "\n",
        "\n",
        "# - The 'test' split on HuggingFace (308 samples) IS the public leaderboard set.\n",
        "# - We treat this as our VALIDATION set ('df_val') to select the best model.\n",
        "# - We also save the train and val to disk, in case dataset from huggingface is updated (e.g., when evaluation phase will start).\n",
        "def load_qevasion_dataset():\n",
        "    if train_path.exists() and val_path.exists():\n",
        "        df_train = pd.read_csv(train_path)\n",
        "        df_val = pd.read_csv(val_path)\n",
        "        return df_train, df_val\n",
        "    else:\n",
        "        dataset = load_dataset(\"ailsntua/QEvasion\")\n",
        "        df_train = dataset[\"train\"].to_pandas()\n",
        "        df_val = dataset[\"test\"].to_pandas()\n",
        "        df_train.to_csv(train_path, index=False)\n",
        "        df_val.to_csv(val_path, index=False)\n",
        "        return df_train, df_val\n",
        "\n",
        "df_train, df_test = load_qevasion_dataset()\n",
        "\n",
        "df_train, df_val = train_test_split(\n",
        "    df_train,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        "    stratify=df_train['evasion_label']\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kB-SEVtpi4A7"
      },
      "outputs": [],
      "source": [
        "# f1_for_class is the exact function used by the authors (they posted it on discord group)\n",
        "def f1_for_class(gold_annotations, predictions, target_class):\n",
        "    \"\"\"\n",
        "    Calculates Precision/Recall/F1 for only one class.\n",
        "\n",
        "    gold_annotations: list of lists (or sets) with labels per sample\n",
        "    predictions: list with one prediction per sample\n",
        "    target_class: the class for which we want the F1\n",
        "    \"\"\"\n",
        "    TP = FP = FN = 0\n",
        "\n",
        "    for gold, pred in zip(gold_annotations, predictions):\n",
        "        gold = set(gold)\n",
        "\n",
        "        if pred == target_class and target_class in gold:\n",
        "            TP += 1  # we correctly predicted target_class\n",
        "        elif pred == target_class and target_class not in gold:\n",
        "            FP += 1  # we predicted target_class but it was not in gold\n",
        "        elif target_class in gold and pred not in gold:\n",
        "            FN += 1  # the class was in gold but the sample is overall wrong\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"tp\": TP, \"fp\": FP, \"fn\": FN}\n",
        "\n",
        "\n",
        "def compute_macro_f1(gold_annotations, predictions):\n",
        "    \"\"\"\n",
        "    Compute Macro-F1 score (same as CodaBench leaderboard).\n",
        "\n",
        "    Args:\n",
        "        gold_annotations: list of lists - each inner list contains valid labels from annotators\n",
        "        predictions: list of strings - one prediction per sample\n",
        "\n",
        "    Returns:\n",
        "        float: Macro F1 score\n",
        "    \"\"\"\n",
        "    all_classes = set()\n",
        "    for gold in gold_annotations:\n",
        "        all_classes.update(gold)\n",
        "    classes = sorted(list(all_classes))\n",
        "\n",
        "    f1_scores = []\n",
        "    for cls in classes:\n",
        "        result = f1_for_class(gold_annotations, predictions, cls)\n",
        "        f1_scores.append(result[\"f1\"])\n",
        "\n",
        "    macro_f1 = float(np.mean(f1_scores))\n",
        "\n",
        "    return macro_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTywfAy1i4A7",
        "outputId": "d53858d6-8ebe-45d8-d50b-1c76bcd68b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes (9): ['Claims ignorance' 'Clarification' 'Declining to answer' 'Deflection'\n",
            " 'Dodging' 'Explicit' 'General' 'Implicit' 'Partial/half-answer']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Alex\\miniconda3\\envs\\312-cuda\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Alex\\.cache\\huggingface\\hub\\models--roberta-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"roberta-base\"\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(df_train['evasion_label'])\n",
        "num_labels = len(label_encoder.classes_)\n",
        "\n",
        "print(f\"Classes ({num_labels}): {label_encoder.classes_}\")\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "fe78bfe1f2f74b5182b4f3cee150a6d6",
            "6c33bda4d7f1422b93addfb984cc9334",
            "d060625075e545e08f5a8ab09bd332fa",
            "a62e8bc5acd44ccc87f0deb4771a6b3e",
            "7fc39c168ee040309a343d6a1a24dfc3",
            "f3d25d509cbf421b9855c2619729526f",
            "14a162f70af04cf89fc627278aac4e67",
            "e63a419771714a7791437f28e50d4883",
            "c17e74cf28ff4e31855dda33d520a164",
            "2650d1831d0040998bc143ffb1342dc9",
            "3bf34bac05b140e09e3b9e494654aee7",
            "4827868d47d94522ac3ac333419703d0",
            "47cc528c95da4b3889b448c5a4341c35",
            "165ce592fa7646b29b47fa853410f12b",
            "0df3c5dfdfba43ff8cc4c38793f22bea",
            "791f6e1a68ce4c8cae5fe97cf6e342d0",
            "18e0863130ec4cd99e4e20b312365c5e",
            "1607243ff2f347b99fe799c62aded619",
            "2e5b48c877244b63848a54ce17fa9a58",
            "f537cf2a882b4d3985ccb2b131c51033",
            "9a9f278462d64ca4ba33fce29be82459",
            "3a8aa3e053554067ad674ef24219900d"
          ]
        },
        "id": "9ns7nny6i4A7",
        "outputId": "505ecef4-cd0f-424d-eec2-7a4b54aab2d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 3103/3103 [00:05<00:00, 615.61 examples/s]\n",
            "Map: 100%|██████████| 345/345 [00:00<00:00, 546.51 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 3103\n",
            "Val samples: 345\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def format_input(row):\n",
        "    \"\"\"Combine question and answer into a single input string.\"\"\"\n",
        "    return f\"Q: {row['question']}\\nA: {row['interview_answer']}\"\n",
        "\n",
        "\n",
        "def prepare_dataset(df, label_encoder):\n",
        "    texts = [format_input(row) for _, row in df.iterrows()]\n",
        "    labels = label_encoder.transform(df['evasion_label']).tolist()\n",
        "    return Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
        "\n",
        "\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=False,\n",
        "    )\n",
        "\n",
        "\n",
        "train_dataset = prepare_dataset(df_train, label_encoder)\n",
        "val_dataset = prepare_dataset(df_val, label_encoder)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "val_dataset = val_dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Val samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR_XNNkbi4A7",
        "outputId": "ba3c3221-8526-4fd6-fccf-e59c968cf767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights:\n",
            "  Claims ignorance: 3.222\n",
            "  Clarification: 4.154\n",
            "  Declining to answer: 2.632\n",
            "  Deflection: 1.005\n",
            "  Dodging: 0.543\n",
            "  Explicit: 0.364\n",
            "  General: 0.994\n",
            "  Implicit: 0.785\n",
            "  Partial/half-answer: 4.856\n"
          ]
        }
      ],
      "source": [
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.arange(num_labels),\n",
        "    y=label_encoder.transform(df_train['evasion_label'])\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "print(\"Class weights:\")\n",
        "for i, cls in enumerate(label_encoder.classes_):\n",
        "    print(f\"  {cls}: {class_weights[i]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S_Bk5QP5i4A7"
      },
      "outputs": [],
      "source": [
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights.to(self.args.device)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        loss_fn = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fn(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szb-zC9Ti4A7",
        "outputId": "9ed42c09-6aff-463f-eb79-f7d302bd5a18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTsjXJHJi4A7"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"model\": MODEL_NAME,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 1e-5,\n",
        "    \"weight_decay\": 0.01,\n",
        "    \"warmup_ratio\": 0.1,\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDpFucmbi4A8"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=str(MODELS_DIR / \"checkpoints\"),\n",
        "    num_train_epochs=config[\"epochs\"],\n",
        "    per_device_train_batch_size=config[\"batch_size\"],\n",
        "    per_device_eval_batch_size=config[\"batch_size\"],\n",
        "    learning_rate=config[\"learning_rate\"],\n",
        "    weight_decay=config[\"weight_decay\"],\n",
        "    warmup_ratio=config[\"warmup_ratio\"],\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "pZKRkuY4i4A8",
        "outputId": "9864e72d-be4e-4eb8-845b-3a3578f28291"
      },
      "outputs": [],
      "source": [
        "trainer = WeightedTrainer(\n",
        "    class_weights=class_weights,\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTfFSM7Ii4A8",
        "outputId": "8e10cd44-c5c7-418c-8793-f02815888d6b"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, tokenizer, label_encoder, df_val):\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, row in df_val.iterrows():\n",
        "            text = format_input(row)\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            pred_idx = outputs.logits.argmax(dim=-1).item()\n",
        "            predictions.append(label_encoder.inverse_transform([pred_idx])[0])\n",
        "\n",
        "    gold_annotations = df_val[['annotator1', 'annotator2', 'annotator3']].values.tolist()\n",
        "    macro_f1 = compute_macro_f1(gold_annotations, predictions)\n",
        "\n",
        "    return macro_f1, predictions\n",
        "\n",
        "\n",
        "macro_f1, predictions = evaluate_model(model, tokenizer, label_encoder, df_test)\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"Macro F1 on Test: {macro_f1:.4f}\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "print(Counter(predictions))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxyvmH1Ui4A8",
        "outputId": "7d0e487a-4729-41b2-9839-7cf21b3361b0"
      },
      "outputs": [],
      "source": [
        "BEST_MODEL_PATH = MODELS_DIR / \"best_model\"\n",
        "\n",
        "model.save_pretrained(BEST_MODEL_PATH)\n",
        "tokenizer.save_pretrained(BEST_MODEL_PATH)\n",
        "joblib.dump(label_encoder, BEST_MODEL_PATH / \"label_encoder.pkl\")\n",
        "\n",
        "with open(BEST_MODEL_PATH / \"metadata.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"config\": config,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"Model saved to {BEST_MODEL_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Run this cell ONLY to generate submission files for CodaBench.**\n",
        "\n",
        "This pipeline will:\n",
        "1. Load your **best saved RoBERTa model** (`best_model/`) from the models directory.\n",
        "2. Download the **\"test\" dataset** from HuggingFace.\n",
        "3. Generate predictions for both:\n",
        "   - **Task 2 (Evasion)**: Direct predictions from the model (9 labels).\n",
        "   - **Task 1 (Clarity)**: Derived by mapping evasion labels to clarity categories (3 labels).\n",
        "4. Save formatted `.zip` files ready for upload to CodaBench.\n",
        "\n",
        "The best model was automatically saved during training based on the highest Macro F1 score on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p74X6GF_i4A8",
        "outputId": "cb2d99da-922f-4c5d-8828-753f6a77fbed"
      },
      "outputs": [],
      "source": [
        "EVASION_TO_CLARITY = {\n",
        "    'Explicit': 'Clear Reply',\n",
        "    'Implicit': 'Ambivalent',\n",
        "    'Dodging': 'Ambivalent',\n",
        "    'General': 'Ambivalent',\n",
        "    'Deflection': 'Ambivalent',\n",
        "    'Partial/half-answer': 'Ambivalent',\n",
        "    'Declining to answer': 'Clear Non-Reply',\n",
        "    'Claims ignorance': 'Clear Non-Reply',\n",
        "    'Clarification': 'Clear Non-Reply',\n",
        "}\n",
        "\n",
        "SUBMISSIONS_DIR = MODELS_DIR / \"submissions\"\n",
        "\n",
        "\n",
        "def load_best_model():\n",
        "    \"\"\"Load best RoBERTa model from disk.\"\"\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_PATH)\n",
        "    tokenizer = RobertaTokenizer.from_pretrained(BEST_MODEL_PATH)\n",
        "    label_encoder = joblib.load(BEST_MODEL_PATH / \"label_encoder.pkl\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    return model, tokenizer, label_encoder\n",
        "\n",
        "\n",
        "def load_test_data():\n",
        "    \"\"\"Download fresh test data from HuggingFace.\"\"\"\n",
        "    dataset = load_dataset(\"ailsntua/QEvasion\")\n",
        "    return dataset[\"test\"].to_pandas()\n",
        "\n",
        "\n",
        "def evasion_to_clarity(y_evasion):\n",
        "    \"\"\"Map evasion labels to clarity labels.\"\"\"\n",
        "    return [EVASION_TO_CLARITY[e] for e in y_evasion]\n",
        "\n",
        "\n",
        "def save_submission(predictions, task_name):\n",
        "    \"\"\"Save predictions as a properly formatted zip for CodaBench.\"\"\"\n",
        "    SUBMISSIONS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    pred_path = SUBMISSIONS_DIR / f\"prediction_{task_name}\"\n",
        "    zip_path = SUBMISSIONS_DIR / f\"submission_{task_name}.zip\"\n",
        "\n",
        "    with open(pred_path, 'w') as f:\n",
        "        f.write('\\n'.join(predictions))\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w') as zf:\n",
        "        zf.write(pred_path, \"prediction\")\n",
        "\n",
        "    return zip_path\n",
        "\n",
        "def generate_submissions():\n",
        "    \"\"\"Full pipeline: load model → predict → save submissions.\"\"\"\n",
        "    best_model, best_tokenizer, best_label_encoder = load_best_model()\n",
        "\n",
        "    df_test = load_test_data()\n",
        "\n",
        "    _, y_evasion = evaluate_model(best_model, best_tokenizer, best_label_encoder, df_test)\n",
        "    y_clarity = evasion_to_clarity(y_evasion)\n",
        "\n",
        "    zip_task2 = save_submission(y_evasion, \"task2\")\n",
        "    zip_task1 = save_submission(y_clarity, \"task1\")\n",
        "\n",
        "    return {\n",
        "        \"task1_zip\": zip_task1,\n",
        "        \"task2_zip\": zip_task2,\n",
        "        \"evasion_dist\": Counter(y_evasion),\n",
        "        \"clarity_dist\": Counter(y_clarity),\n",
        "    }\n",
        "\n",
        "\n",
        "results = generate_submissions()\n",
        "results\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "312-cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0df3c5dfdfba43ff8cc4c38793f22bea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9f278462d64ca4ba33fce29be82459",
            "placeholder": "​",
            "style": "IPY_MODEL_3a8aa3e053554067ad674ef24219900d",
            "value": " 345/345 [00:01&lt;00:00, 175.52 examples/s]"
          }
        },
        "14a162f70af04cf89fc627278aac4e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1607243ff2f347b99fe799c62aded619": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "165ce592fa7646b29b47fa853410f12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5b48c877244b63848a54ce17fa9a58",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f537cf2a882b4d3985ccb2b131c51033",
            "value": 345
          }
        },
        "18e0863130ec4cd99e4e20b312365c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2650d1831d0040998bc143ffb1342dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5b48c877244b63848a54ce17fa9a58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8aa3e053554067ad674ef24219900d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bf34bac05b140e09e3b9e494654aee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47cc528c95da4b3889b448c5a4341c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e0863130ec4cd99e4e20b312365c5e",
            "placeholder": "​",
            "style": "IPY_MODEL_1607243ff2f347b99fe799c62aded619",
            "value": "Map: 100%"
          }
        },
        "4827868d47d94522ac3ac333419703d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47cc528c95da4b3889b448c5a4341c35",
              "IPY_MODEL_165ce592fa7646b29b47fa853410f12b",
              "IPY_MODEL_0df3c5dfdfba43ff8cc4c38793f22bea"
            ],
            "layout": "IPY_MODEL_791f6e1a68ce4c8cae5fe97cf6e342d0"
          }
        },
        "6c33bda4d7f1422b93addfb984cc9334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d25d509cbf421b9855c2619729526f",
            "placeholder": "​",
            "style": "IPY_MODEL_14a162f70af04cf89fc627278aac4e67",
            "value": "Map: 100%"
          }
        },
        "791f6e1a68ce4c8cae5fe97cf6e342d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc39c168ee040309a343d6a1a24dfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a9f278462d64ca4ba33fce29be82459": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62e8bc5acd44ccc87f0deb4771a6b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2650d1831d0040998bc143ffb1342dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_3bf34bac05b140e09e3b9e494654aee7",
            "value": " 3103/3103 [00:09&lt;00:00, 350.30 examples/s]"
          }
        },
        "c17e74cf28ff4e31855dda33d520a164": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d060625075e545e08f5a8ab09bd332fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e63a419771714a7791437f28e50d4883",
            "max": 3103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c17e74cf28ff4e31855dda33d520a164",
            "value": 3103
          }
        },
        "e63a419771714a7791437f28e50d4883": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d25d509cbf421b9855c2619729526f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f537cf2a882b4d3985ccb2b131c51033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe78bfe1f2f74b5182b4f3cee150a6d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c33bda4d7f1422b93addfb984cc9334",
              "IPY_MODEL_d060625075e545e08f5a8ab09bd332fa",
              "IPY_MODEL_a62e8bc5acd44ccc87f0deb4771a6b3e"
            ],
            "layout": "IPY_MODEL_7fc39c168ee040309a343d6a1a24dfc3"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
